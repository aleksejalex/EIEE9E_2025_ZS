{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aleksejalex/EIEE9E_2025_ZS/blob/main/PyPEF_06_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJ38-zM8iNpQ"
      },
      "source": [
        "# PyPEF, lecture 06. Handling data in Python.\n",
        "\n",
        "Prepared by: Aleksej Gaj ( pythonforstudents24@gmail.com )\n",
        "\n",
        "üîó Course website: [https://aleksejgaj.cz/pef_python/](https://aleksejgaj.cz/pef_python/)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXm-Hf4n8dXz"
      },
      "source": [
        "*Note:* this notebook is partially inspired by [this notebook](https://github.com/janpipek/fbmi-python-course/blob/main/notebooks/130_pandas_intro.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZEI2YaSwiPFc"
      },
      "source": [
        "In this tutorial we will learn how to work with data in Python, namely:\n",
        "- how `pandas` library stores data\n",
        "- how to import data and change it\n",
        "- basic functionality of `pandas` library\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "PQx6yQAYboV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Remark: load numpy.array from CSV file"
      ],
      "metadata": {
        "id": "9CChfUNRmX31"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile sample_data.csv\n",
        "Column1,Column2,Column3\n",
        "1,4,7\n",
        "2,5,8\n",
        "3,6,9"
      ],
      "metadata": {
        "id": "AS4H_YtEmYSp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the CSV file into a NumPy array\n",
        "array = np.loadtxt('sample_data.csv', delimiter=',', skiprows=1)\n",
        "print(array)"
      ],
      "metadata": {
        "id": "x6k6gUeZmfln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1goALDC68dX9"
      },
      "source": [
        "## üìä Data: blessing and curse\n",
        "\n",
        "Nowadays, the importance of data is obvious.\n",
        "\n",
        "When working with data, remember:\n",
        "\n",
        "1) no perfect data exist: any dataset is obtained as the result of some experiment/observation, so there arise problems like:\n",
        "   - **missing data**: not every property of every individual was recorded/obtained (*example:* some people prefer not to say their gender)\n",
        "   - **low quality**: inconsistent values (*How to deal with outliers?*), incorrect formatting, duplicate records,\n",
        "   - **data imbalance:** definitely not all situations occured, some might be underrepresented/overrepresented (*How it comes NN is rasist*)\n",
        "\n",
        "2) there are several ways how to analyse the data, and always many ways, how to *interpret* the results:\n",
        "   - two analysts can deduce different conclusions from *the same data*\n",
        "   - context (how? why?) matters, but often even client has no clue how the data were observed and what questions are expected to be answered (why?)\n",
        "   - *analysis of data is more like an art, and interpretation is sometimes close to philosophy*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jc9MasC8dX9"
      },
      "source": [
        "üëâ So:\n",
        " - do not analyse data as some kind of routine (unless it is routine): be sure you **understand the phenomena** behind your data and **formulate your task accordingly**\n",
        " - try to **get as much context** (additional information) about your data as possible. It might happen that \"the mistake\" was done already during collecting or preprocessing phase\n",
        " - try to get your hands **on raw data** (in many cases wrong preprocessing kills the valuable infomation in the data)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FgQAjs3Z8dX9"
      },
      "source": [
        "üö®üö®üö® **Warning:** Data analysis and data science are huge areas comprising interdisciplinatry knowledge in probabilisty, statistics, optimisation, etc and programming art and dark magic. There is no chance to cover even brief introduction in this course. However, we will try to learn *how* to use the most popular tools, expecting you will learn *why* to use them in other tasks (or in others subjects).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-8tknQQ8dX9"
      },
      "source": [
        "Something to avoid:\n",
        "\n",
        "<img src=\"https://imgs.xkcd.com/comics/flawed_data.png\" alt=\"logo\" width=\"600\">\n",
        "\n",
        "source: [xkcd.com](https://xkcd.com/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvpypSBg8dX-"
      },
      "source": [
        "## Data in Python: pandas\n",
        "<img src=\"https://pandas.pydata.org/pandas-docs/stable/_static/pandas.svg\" alt=\"logo\" width=\"200\">\n",
        "\n",
        " = Python library for data manipulation and analysis\n",
        "\n",
        " - nothing in common with üêº, name is derived from \"**pan**el **da**ta\" (=econometric term for data sets that include observations over time of the same individuals)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKvIr4Hd8dX-"
      },
      "source": [
        "*Reminder of literature:*\n",
        " - the book written by the creator of Pandas - Wes McKinney\n",
        "\n",
        "<img src=\"https://aleksejalex.4fan.cz/imgsbin/uploads/mckinney_rejsek.png\" alt=\"logo\" width=\"150\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdeyBhSO8dX-"
      },
      "source": [
        "Now let's get to technicalities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F2Ojs_er8dX-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "riV9g_AA8dX-"
      },
      "source": [
        "### Basic objects\n",
        "\n",
        " - Series\n",
        " - DataFrame"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5doTT7ow8dX-"
      },
      "source": [
        "#### Series\n",
        " = basic element of pandas, similar to array in NumPy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g5aP3EN68dX-"
      },
      "outputs": [],
      "source": [
        "series = pd.Series([101, 102, 103])\n",
        "series"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m4KKB45J8dX-"
      },
      "outputs": [],
      "source": [
        "series.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uD_rmiWrN_Ni"
      },
      "outputs": [],
      "source": [
        "type(series.values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csjZedTe8dX_"
      },
      "source": [
        "Ah! So `pd.Series` is just a wrapper for `np.ndarray`? ü§î\n",
        "\n",
        "No, there's more: `pd.Series` contains not only the data (as numpy does), but also it assigns some \"label\" to each row. The \"label\" is called index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bs3Ck2b4N_Ni"
      },
      "outputs": [],
      "source": [
        "series.index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLLaIKRm8dX_"
      },
      "source": [
        "Index can be used to access some part of `pd.Series`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YE-txWaB8dX_"
      },
      "outputs": [],
      "source": [
        "series[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gq9rtdC58dX_"
      },
      "outputs": [],
      "source": [
        "# series from a dictionary\n",
        "series_ab = pd.Series({\"a\": 2, \"b\": 4})\n",
        "series_ab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8F9ag458dYB"
      },
      "source": [
        "#### DataFrame\n",
        " = something like Excel table üôÇ\n",
        "\n",
        " ‚ûï Python friendly (simple interaction with other libraries) \\\n",
        " ‚ûï much faster than Excel  \\\n",
        " ‚ûñ no GUI to edit data (at least not as a part of pandas) \\\n",
        " ‚ûñ you don't modify the data, you create a copy with modified values  \\\n",
        " ‚ûñ slow and demanding - whole data need to be loaded into RAM (but still faster than Excel üòú )\n",
        "\n",
        "Technically - a collection of named columns (collection of `pd.Series`)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9TnMglln8dYB"
      },
      "source": [
        "### Main Features of pandas.DataFrame:\n",
        "\n",
        "1. Tabular Data Structure\n",
        "2. Data Handling for Heterogeneous Data Types\n",
        "3. Indexing for Easy Data Access\n",
        "4. Data Manipulation Functions\n",
        "5. Missing Data Handling Methods\n",
        "6. Grouping and Aggregation Capabilities\n",
        "7. Data Cleaning and Preprocessing Tools\n",
        "8. Data Import and Export Functions\n",
        "9. Integration with Data Visualization Libraries\n",
        "\n",
        "### Comparison with Excel:\n",
        "\n",
        "| Feature         | pandas.DataFrame                  | MS Excel                                 |\n",
        "|-----------------|-----------------------------------|---------------------------------------|\n",
        "| Scalability     | Efficient for Larger Datasets     | Limited by Memory                     |\n",
        "| Control         | Programmatic Automation           | Manual Operations                     |\n",
        "| Performance     | Better for Complex Operations     | Slower for Large Datasets             |\n",
        "| Integration     | Seamless with Python Ecosystem    | Standalone Application                |\n",
        "| Customization   | Extensive Flexibility             | Limited to Built-in Functions         |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OP2OC1j8dYB"
      },
      "source": [
        "Back to code: ways to create dataframe \"by hand\":"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vFoshECF8dYB"
      },
      "outputs": [],
      "source": [
        "# specify columns as 'pd.Series':\n",
        "df = pd.DataFrame({\n",
        "    'number': pd.Series([1, 2, 3, 4], dtype = np.int64),\n",
        "    'letter': pd.Series(['a', 'b', 'c', 'd'])\n",
        "})\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ei-RWVI68dYB"
      },
      "outputs": [],
      "source": [
        "# create dataframe from `dict`:\n",
        "df_cars = pd.DataFrame(\n",
        "    {\n",
        "        \"name\": ['Audi', 'BMW', 'Citroen'],\n",
        "        \"age\": [8, 12, 1],\n",
        "        \"used\": [True, True, False],\n",
        "        \"price\": [10000, 25000, 11000]\n",
        "    }\n",
        ")\n",
        "\n",
        "df_cars"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fylhLQZn8dYB"
      },
      "source": [
        "Let's check type of variables in df:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "54u2rBOf8dYB"
      },
      "outputs": [],
      "source": [
        "df_cars.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j3rvL1fY8dYB"
      },
      "outputs": [],
      "source": [
        "df_cars.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCrQuQEe8dYB"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zUymTNpC8dYC"
      },
      "outputs": [],
      "source": [
        "df_cars.set_index('name', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dMyKTouq8dYC"
      },
      "outputs": [],
      "source": [
        "df_cars"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOaphOZc8dYC"
      },
      "source": [
        "Different way how to create an index when creating a df:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UNt-Yqn88dYC"
      },
      "outputs": [],
      "source": [
        "df_cars = pd.DataFrame(\n",
        "    {\n",
        "        \"name\": ['Audi', 'BMW', 'Citroen'],\n",
        "        \"age\": [8, 12, 1],\n",
        "        \"used\": [True, True, False],\n",
        "        \"price\": [10000, 25000, 11000]\n",
        "    }, index = ['car1', 'car2', 'car3']   # note the index we specify\n",
        ")\n",
        "\n",
        "df_cars"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbNcCibB8dYC"
      },
      "source": [
        "Now the \"individuals\" are indexed not via numbers, but via our own indexes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGD3leEk8dYC"
      },
      "source": [
        "### How to access elements?\n",
        "\n",
        "There are two ways how to access them:\n",
        " - using `loc` function for label-based indexing\n",
        " - using `iloc` for order-based indexing\n",
        "\n",
        "‚ùó Note the square brackets:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "znq2hGOn8dYD"
      },
      "outputs": [],
      "source": [
        "df_cars.loc[\"car1\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Ifa78468dYD"
      },
      "outputs": [],
      "source": [
        "df_cars.iloc[0]  # first entry is Audi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lCPHsEoa8dYD"
      },
      "source": [
        "How to write out a single column form df?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Yyz2ZAk8dYD"
      },
      "outputs": [],
      "source": [
        "df_cars[\"price\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EsTHgGx38dYE"
      },
      "source": [
        "The column should be `pd.Series`, right?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tJlHfBkH8dYE"
      },
      "outputs": [],
      "source": [
        "type(df_cars[\"price\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0w3k6tw8dYE"
      },
      "source": [
        "### Importing data to pandas\n",
        "\n",
        " - in pandas I/O is very simple and convenient. You can import (and export) to huge amount of formats:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUGrrl8v8dYE"
      },
      "source": [
        "| File Format            | Short Comment                                     | Example Command                                   |\n",
        "|------------------------|---------------------------------------------------|---------------------------------------------------|\n",
        "| CSV (Comma-Separated Values) | Common text-based format for tabular data.   | `pd.read_csv('data.csv')`                     |\n",
        "| Excel Spreadsheet     | Popular format for storing data in sheets.         | `pd.read_excel('data.xlsx')`                      |\n",
        "| JSON (JavaScript Object Notation) | Lightweight data interchange format.        | `pd.read_json('data.json')`                     |\n",
        "| SQL Database           | Import data from SQL databases using SQLAlchemy.   | `pd.read_sql('SELECT * FROM table_name', connection)` |\n",
        "| HTML tables            | Extract tables from HTML documents.                | `pd.read_html('page.html')`                      |\n",
        "| HDF5 (hierarchical data format version 5) | Designed for storing large amounts of data. | `pd.read_hdf('data.h5', 'key')`                   |\n",
        "| Feather                | Fast, lightweight binary columnar data format.     | `pd.read_feather('data.feather')`                |\n",
        "| Parquet                | Columnar storage format optimized for analytics.   | `pd.read_parquet('data.parquet')`                |\n",
        "| Msgpack                | Efficient binary serialization format.             | `pd.read_msgpack('data.msgpack')`                |\n",
        "| Stata                  | Popular format for social science research data.   | `pd.read_stata('data.dta')`                      |\n",
        "| SAS                    | Statistical Analysis System format.                | `pd.read_sas('data.sas7bdat')`                   |\n",
        "| SPSS                   | Statistical Package for the Social Sciences format.| `pd.read_spss('data.sav')`                       |\n",
        "| Google BigQuery        | Import data from Google BigQuery database tables.  | `pd.read_gbq('SELECT * FROM table_name', project_id)` |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVYuN7OI8dYE"
      },
      "source": [
        "Let's try it:\n",
        " - create `.csv` file (for simplicity we will use magic of jupyter notebooks, but locally you can import any local file)\n",
        " - load in pandas\n",
        " - print it out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oL97s5nk8dYF"
      },
      "source": [
        "(source: [Kaggle](https://www.kaggle.com/datasets/crawford/80-cereals))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EaJS-6-u8dYF"
      },
      "outputs": [],
      "source": [
        "%%writefile cereals.csv\n",
        "name,mfr,type_of,calories,protein,fat,sodium,fiber,carbo,sugars,potass,vitamins,shelf,weight,cups,rating\n",
        "100% Bran,N,C,70,4,1,130,10,5,6,280,25,3,1,0.33,68.402973\n",
        "100% Natural Bran,Q,C,120,3,5,15,2,8,8,135,0,3,1,1,33.983679\n",
        "All-Bran,K,C,70,4,1,260,9,7,5,320,25,3,1,0.33,59.425505\n",
        "All-Bran with Extra Fiber,K,C,50,4,0,140,14,8,0,330,25,3,1,0.5,93.704912\n",
        "Almond Delight,R,C,110,2,2,200,1,14,8,-1,25,3,1,0.75,34.384843\n",
        "Apple Cinnamon Cheerios,G,C,110,2,2,180,1.5,10.5,10,70,25,1,1,0.75,29.509541\n",
        "Apple Jacks,K,C,110,2,0,125,1,11,14,30,25,2,1,1,33.174094\n",
        "Basic 4,G,C,130,3,2,210,2,18,8,100,25,3,1.33,0.75,37.038562\n",
        "Bran Chex,R,C,90,2,1,200,4,15,6,125,25,1,1,0.67,49.120253\n",
        "Bran Flakes,P,C,90,3,0,210,5,13,5,190,25,3,1,0.67,53.313813\n",
        "Cap'n'Crunch,Q,C,120,1,2,220,0,12,12,35,25,2,1,0.75,18.042851\n",
        "Cheerios,G,C,110,6,2,290,2,17,1,105,25,1,1,1.25,50.764999\n",
        "Cinnamon Toast Crunch,G,C,120,1,3,210,0,13,9,45,25,2,1,0.75,19.823573\n",
        "Clusters,G,C,110,3,2,140,2,13,7,105,25,3,1,0.5,40.400208\n",
        "Cocoa Puffs,G,C,110,1,1,180,0,12,13,55,25,2,1,1,22.736446\n",
        "Corn Chex,R,C,110,2,0,280,0,22,3,25,25,1,1,1,41.445019\n",
        "Corn Flakes,K,C,100,2,0,290,1,21,2,35,25,1,1,1,45.863324\n",
        "Corn Pops,K,C,110,1,0,90,1,13,12,20,25,2,1,1,35.782791\n",
        "Count Chocula,G,C,110,1,1,180,0,12,13,65,25,2,1,1,22.396513\n",
        "Cracklin' Oat Bran,K,C,110,3,3,140,4,10,7,160,25,3,1,0.5,40.448772\n",
        "Cream of Wheat (Quick),N,H,100,3,0,80,1,21,0,-1,0,2,1,1,64.533816\n",
        "Crispix,K,C,110,2,0,220,1,21,3,30,25,3,1,1,46.895644\n",
        "Crispy Wheat & Raisins,G,C,100,2,1,140,2,11,10,120,25,3,1,0.75,36.176196\n",
        "Double Chex,R,C,100,2,0,190,1,18,5,80,25,3,1,0.75,44.330856\n",
        "Froot Loops,K,C,110,2,1,125,1,11,13,30,25,2,1,1,32.207582\n",
        "Frosted Flakes,K,C,110,1,0,200,1,14,11,25,25,1,1,0.75,31.435973\n",
        "Frosted Mini-Wheats,K,C,100,3,0,0,3,14,7,100,25,2,1,0.8,58.345141\n",
        "Fruit & Fibre Dates Walnuts and Oats,P,C,120,3,2,160,5,12,10,200,25,3,1.25,0.67,40.917047\n",
        "Fruitful Bran,K,C,120,3,0,240,5,14,12,190,25,3,1.33,0.67,41.015492\n",
        "Fruity Pebbles,P,C,110,1,1,135,0,13,12,25,25,2,1,0.75,28.025765\n",
        "Golden Crisp,P,C,100,2,0,45,0,11,15,40,25,1,1,0.88,35.252444\n",
        "Golden Grahams,G,C,110,1,1,280,0,15,9,45,25,2,1,0.75,23.804043\n",
        "Grape Nuts Flakes,P,C,100,3,1,140,3,15,5,85,25,3,1,0.88,52.076897\n",
        "Grape-Nuts,P,C,110,3,0,170,3,17,3,90,25,3,1,0.25,53.371007\n",
        "Great Grains Pecan,P,C,120,3,3,75,3,13,4,100,25,3,1,0.33,45.811716\n",
        "Honey Graham Ohs,Q,C,120,1,2,220,1,12,11,45,25,2,1,1,21.871292\n",
        "Honey Nut Cheerios,G,C,110,3,1,250,1.5,11.5,10,90,25,1,1,0.75,31.072217\n",
        "Honey-comb,P,C,110,1,0,180,0,14,11,35,25,1,1,1.33,28.742414\n",
        "Just Right Crunchy  Nuggets,K,C,110,2,1,170,1,17,6,60,100,3,1,1,36.523683\n",
        "Just Right Fruit & Nut,K,C,140,3,1,170,2,20,9,95,100,3,1.3,0.75,36.471512\n",
        "Kix,G,C,110,2,1,260,0,21,3,40,25,2,1,1.5,39.241114\n",
        "Life,Q,C,100,4,2,150,2,12,6,95,25,2,1,0.67,45.328074\n",
        "Lucky Charms,G,C,110,2,1,180,0,12,12,55,25,2,1,1,26.734515\n",
        "Maypo,A,H,100,4,1,0,0,16,3,95,25,2,1,1,54.850917\n",
        "Muesli Raisins Dates & Almonds,R,C,150,4,3,95,3,16,11,170,25,3,1,1,37.136863\n",
        "Muesli Raisins Peaches & Pecans,R,C,150,4,3,150,3,16,11,170,25,3,1,1,34.139765\n",
        "Mueslix Crispy Blend,K,C,160,3,2,150,3,17,13,160,25,3,1.5,0.67,30.313351\n",
        "Multi-Grain Cheerios,G,C,100,2,1,220,2,15,6,90,25,1,1,1,40.105965\n",
        "Nut&Honey Crunch,K,C,120,2,1,190,0,15,9,40,25,2,1,0.67,29.924285\n",
        "Nutri-Grain Almond-Raisin,K,C,140,3,2,220,3,21,7,130,25,3,1.33,0.67,40.692320\n",
        "Nutri-grain Wheat,K,C,90,3,0,170,3,18,2,90,25,3,1,1,59.642837\n",
        "Oatmeal Raisin Crisp,G,C,130,3,2,170,1.5,13.5,10,120,25,3,1.25,0.5,30.450843\n",
        "Post Nat. Raisin Bran,P,C,120,3,1,200,6,11,14,260,25,3,1.33,0.67,37.840594\n",
        "Product 19,K,C,100,3,0,320,1,20,3,45,100,3,1,1,41.503540\n",
        "Puffed Rice,Q,C,50,1,0,0,0,13,0,15,0,3,0.5,1,60.756112\n",
        "Puffed Wheat,Q,C,50,2,0,0,1,10,0,50,0,3,0.5,1,63.005645\n",
        "Quaker Oat Squares,Q,C,100,4,1,135,2,14,6,110,25,3,1,0.5,49.511874\n",
        "Quaker Oatmeal,Q,H,100,5,2,0,2.7,-1,-1,110,0,1,1,0.67,50.828392\n",
        "Raisin Bran,K,C,120,3,1,210,5,14,12,240,25,2,1.33,0.75,39.259197\n",
        "Raisin Nut Bran,G,C,100,3,2,140,2.5,10.5,8,140,25,3,1,0.5,39.703400\n",
        "Raisin Squares,K,C,90,2,0,0,2,15,6,110,25,3,1,0.5,55.333142\n",
        "Rice Chex,R,C,110,1,0,240,0,23,2,30,25,1,1,1.13,41.998933\n",
        "Rice Krispies,K,C,110,2,0,290,0,22,3,35,25,1,1,1,40.560159\n",
        "Shredded Wheat,N,C,80,2,0,0,3,16,0,95,0,1,0.83,1,68.235885\n",
        "Shredded Wheat'n'Bran,N,C,90,3,0,0,4,19,0,140,0,1,1,0.67,74.472949\n",
        "Shredded Wheat spoon size,N,C,90,3,0,0,3,20,0,120,0,1,1,0.67,72.801787\n",
        "Smacks,K,C,110,2,1,70,1,9,15,40,25,2,1,0.75,31.230054\n",
        "Special K,K,C,110,6,0,230,1,16,3,55,25,1,1,1,53.131324\n",
        "Strawberry Fruit Wheats,N,C,90,2,0,15,3,15,5,90,25,2,1,1,59.363993\n",
        "Total Corn Flakes,G,C,110,2,1,200,0,21,3,35,100,3,1,1,38.839746\n",
        "Total Raisin Bran,G,C,140,3,1,190,4,15,14,230,100,3,1.5,1,28.592785\n",
        "Total Whole Grain,G,C,100,3,1,200,3,16,3,110,100,3,1,1,46.658844\n",
        "Triples,G,C,110,2,1,250,0,21,3,60,25,3,1,0.75,39.106174\n",
        "Trix,G,C,110,1,1,140,0,13,12,25,25,2,1,1,27.753301\n",
        "Wheat Chex,R,C,100,3,1,230,3,17,3,115,25,1,1,0.67,49.787445\n",
        "Wheaties,G,C,100,3,1,200,3,17,3,110,25,1,1,1,51.592193\n",
        "Wheaties Honey Gold,G,C,110,2,1,200,1,16,8,60,25,1,1,0.75,36.187559"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c0SP_38S8dYG"
      },
      "outputs": [],
      "source": [
        "df_cereals = pd.read_csv(\"cereals.csv\", delimiter=',')\n",
        "df_cereals.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxocN9BZ8dYG"
      },
      "source": [
        "Impractical, right? Luckily pandas can directly read from weblink:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XmwQhGCO8dYG"
      },
      "outputs": [],
      "source": [
        "del df_cereals\n",
        "\n",
        "df_cereals = pd.read_csv(\"https://gist.githubusercontent.com/aleksejalex/26a83646c03120af1eaeb117572d895e/raw/2ddc8661d86fbf1b7d09204ff39fdf74ce3723b6/cereals.csv\", delimiter=',')\n",
        "df_cereals.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MHgURknx8dYG"
      },
      "source": [
        "Now let's have a little fun with those data:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bh4EweT_8dYG"
      },
      "source": [
        "### Show the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "drKbh6mf8dYG"
      },
      "outputs": [],
      "source": [
        "df_cereals.head(8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y5juH1158dYG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBCXoe__8dYH"
      },
      "source": [
        "### Check for types and retype if needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gEv5El_H8dYH"
      },
      "outputs": [],
      "source": [
        "df_cereals.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6V6C2KHP8dYH"
      },
      "outputs": [],
      "source": [
        "df_cereals[\"calories\"] = df_cereals[\"calories\"].astype('float')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D1xVOasw8dYH"
      },
      "outputs": [],
      "source": [
        "df_cereals[\"type_of\"] = df_cereals[\"type_of\"].astype(\"category\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s3IxeaqA8dYH"
      },
      "outputs": [],
      "source": [
        "df_cereals.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTOtKKBW8dYI"
      },
      "source": [
        "### Know your data - basic statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gqBQB4Y18dYI"
      },
      "outputs": [],
      "source": [
        "df_cereals.describe(include='all')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xXdC2i1T8dYI"
      },
      "source": [
        "### plot your data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vR-Clkac8dYI"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tRxdCQ8s8dYI"
      },
      "outputs": [],
      "source": [
        "plt.figure()\n",
        "plt.plot(df_cereals[\"calories\"], label=\"calories\")\n",
        "plt.plot(df_cereals[\"protein\"], label=\"proteins\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xKVjsUDu8dYI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_o4fRKk8dYJ"
      },
      "source": [
        "## Optional homework: 2 alternatives:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tcv_sbUw8dYJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5NKoSfs8dYJ"
      },
      "source": [
        "### Option 1: work with your own data\n",
        "**task:** Create a dataframe, containing some of your subjects. Each subject should have these properties: shortcut, number of credits, boolean value if it's optional or obligatory, and room number where lectures takes place (for example for E455 `room=455`).\n",
        "\n",
        "1) create such dataframe\n",
        "2) compute basic statistics (average amount of credits? do you have more optional subjects than obligatory? how often do you visit odd floors for lectures?) consider writing simple functions for some of questions. Feel free to answer your own questions about your data.\n",
        "3) make basic plots. Consider which variables makes sense to plot and how. Use subplots if it makes sense."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wP4mfYTo8dYK"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcvVP93V8dYK"
      },
      "source": [
        "### Option 2: work withcereals data\n",
        "**task:** same as above, but for cereals dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RNOGDYjC8dYK"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "generative_ai_disabled": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}