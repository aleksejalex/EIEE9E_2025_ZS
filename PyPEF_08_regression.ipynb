{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aleksejalex/EIEE9E_2025_ZS/blob/main/PyPEF_08_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BJ38-zM8iNpQ"
      },
      "source": [
        "# PyPEF, lecture 08. Linear regression.\n",
        "\n",
        "Prepared by: Aleksej Gaj ( pythonforstudents24@gmail.com )\n",
        "\n",
        "üîó Course website: [https://aleksejgaj.cz/pef_python/](https://aleksejgaj.cz/pef_python/)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tyCPg2kcaLi"
      },
      "source": [
        "üëâ Technical note: Numbering of the notebooks is a little messed up:\n",
        " - use links from the subject's webpage, those should be OK.\n",
        "\n",
        " (if you spot some inconsistency, please feel free to email me)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkBG6zRycaLi"
      },
      "source": [
        "### Two basic tasks/approaches:\n",
        "\n",
        " - **regression** = fitting a \"shape\" to data as close as possible\n",
        "\n",
        "<img src=\"https://higherlogicdownload.s3.amazonaws.com/IMWUC/UploadedImages/92757287-d116-4157-b004-c2a0aba1b048/linear-regression-in-machine-learning.png\" alt=\"banner\" width=\"300\" align=\"center\"><br>\n",
        " *Examples:* predict the age of a cat based on its weight, predict price of a house based on its size and location, predict failure of some kind of machinery, ...\n",
        "\n",
        " - **classification** = separating data into classes (response is represented by discrete values)\n",
        "\n",
        "<img src=\"https://miro.medium.com/v2/resize:fit:980/1*wm5m2Wd0gMXAkztc7vP7yA.png\" alt=\"banner\" width=\"260\" align=\"center\"><br>\n",
        "*Examples:* predict whether the creature is mammal or not, predict whether there is a man or woman on the picture, predict what scene is on the video, ...\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dGsGW5_hcaLj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypRX75lUcaLj"
      },
      "source": [
        "## scikit-learn\n",
        "<a href=\"https://scikit-learn.org/stable/index.html\"><img src=\"https://scikit-learn.org/stable/_static/scikit-learn-logo-small.png\" alt=\"banner\" width=\"220\" align=\"right\"></a>\n",
        " = library offering algorithms for classification, regression, clustering, etc.\n",
        " - user friendly, doesn't require deep knowledge\n",
        " - compatible with NumPy, SciPy, matplotlib and Pandas\n",
        " - has very nice documentation [here](https://scikit-learn.org/stable/index.html)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {},
        "id": "KOiBoq12caLk"
      },
      "outputs": [],
      "source": [
        "# imports for today (we are already familiar with those libraries)\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFnK3GK0caLl"
      },
      "source": [
        "In case you will need to install this package:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {},
        "id": "FesoW1DMcaLl"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%pip install scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dj6usDR6caLm"
      },
      "source": [
        "## A few useful things to learn:\n",
        "Before we get to ML, let's get familiar with some functions we will use:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JcpOf7bcaLn"
      },
      "source": [
        " - **generate random data in specific way** (so you can easily train your classifying skills)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3xHG725acaLn"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import make_blobs\n",
        "\n",
        "# Generate random data using make_blobs\n",
        "num_samples = 15\n",
        "x, y = make_blobs(n_samples=num_samples, centers=2, cluster_std=1.3, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HL9_VQLacaLn"
      },
      "source": [
        "function output are pairs, each pair is: $(\\vec{x}, y)$, where:\n",
        " - $y \\in \\lbrace 0, 1, 2, ... N \\rbrace $, where $N$ is number of classes ... index, to which class the observation belongs\n",
        " - $\\vec{x} = (x_1, x_2, ..., x_a)$, where $x_j$ is a value of $j$-th feature ... vector of features (example: if our observation are customers, their features can be: age, gender, amount of spent money, ...)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nTkhgyYWcaLo"
      },
      "outputs": [],
      "source": [
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-mkhShAwcaLo"
      },
      "outputs": [],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O4zUFhZocaLo"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(4, 3))\n",
        "plt.scatter(x[:, 0], x[:, 1], c=y, cmap='viridis', marker='o')\n",
        "plt.title('Visualization of Blobs')\n",
        "plt.xlabel('Feature 1')\n",
        "plt.ylabel('Feature 2')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kj_aFgQhcaLp"
      },
      "source": [
        "<a href=\"https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Fmedia.geeksforgeeks.org%2Fwp-content%2Fcdn-uploads%2F20190523171258%2Foverfitting_2.png&f=1&nofb=1&ipt=042ce96dbef98d7aa8ba54ca1e90ce3d0132347982c54dd1ca7580e6da8411e3&ipo=images\"><img src=\"https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Fmedia.geeksforgeeks.org%2Fwp-content%2Fcdn-uploads%2F20190523171258%2Foverfitting_2.png&f=1&nofb=1&ipt=042ce96dbef98d7aa8ba54ca1e90ce3d0132347982c54dd1ca7580e6da8411e3&ipo=images\" alt=\"banner\" width=\"600\" align=\"right\"></a>\n",
        " - function that splits our data (`X, y`) into training dataset and testing dataset.\n",
        "This is needed to evaluate how successful are the predictions of our model on those data that it hasn't seen. (The ability to extrapolate is important.)\n",
        "\n",
        "Also this helps to avoid overfitting: if model learns to much from our data, it starts to remember not only the main pattern, but also things like random noise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mMmn3buScaLp"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b1v_LtnkcaLp"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6De0NqR-caLp"
      },
      "outputs": [],
      "source": [
        "print(f\"size of x = {x.shape}\")\n",
        "print(f\"size of X_train = {X_train.shape}\")\n",
        "print(f\"size of X_test = {X_test.shape}\")\n",
        "print(f\"size of y = {y.shape}\")\n",
        "print(f\"size of y_train = {y_train.shape}\")\n",
        "print(f\"size of y_test = {y_test.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SZhWdXUNcaLq"
      },
      "outputs": [],
      "source": [
        "# we don't want to mess with different variables onder same name, so:\n",
        "del(x, y, X_train, X_test, y_train, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ei1cZYMtcaLq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_fux15ucaLq"
      },
      "source": [
        "## Linear regression - most common tool\n",
        " - intuitively: the algorithm tries to find optimal coefficients of a line to interpolate the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TE3iYdwZcaLq"
      },
      "source": [
        "### The idea behind fitting:\n",
        "*find coefficients of the line (slope and intercept) such that total sum of distances `datapoint<->line` is minimised*\n",
        "\n",
        "<img src=\"https://aleksejalex.4fan.cz/imgsbin/uploads/regression_animation.gif\" width=\"400\" >\n",
        "\n",
        "(Unfortunately credits lost, probably [this](https://www.youtube.com/watch?v=lorPvqyGsZU&t=4s) or [this](https://dataphys.org/list/doing-regression-with-a-cardboard-straw-and-strings/))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Intuition behind\n",
        " - It shows the **trend**: how one variable changes when another changes.\n",
        "\n",
        "   **Example:** `(Hours studied) ‚Üí (Exam score)` The line helps you **predict** the score for any number of hours.\n",
        "\n",
        " - we estimate or ‚Äúpull back toward‚Äù the best-fitting line\n",
        " - we are not assuming growth, only trying to describe a relationship\n",
        "\n",
        "\n",
        "### ü§î Why it's called \"regression\"\n",
        "The term regression comes from a 19th-century statistician, Francis Galton.\n",
        "He noticed that:\n",
        "\n",
        " - very tall parents had children who were tall, but a little closer to average\n",
        "\n",
        " - very short parents had children who were short, but also closer to average\n",
        "\n",
        "He called this:\n",
        "```\n",
        "‚Äúregression to the mean‚Äù\n",
        "```\n",
        "The name stuck.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Mn2E67K3f0B0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trivial example:\n",
        "‚úÖ **1. A line that best fits your data**\n",
        "\n",
        "Imagine you plot pairs of numbers on a graph‚Äîfor example:\n",
        " - hours studied (x)\n",
        " - exam score (y)\n",
        "\n",
        "The dots may look scattered.\n",
        "Linear regression draws the straight line that best fits those dots.\n",
        "\n",
        "‚úÖ **2. The line helps you predict**\n",
        "\n",
        "If you know the line, then:\n",
        "```\n",
        "If a student studies 5 hours, what score do we expect?\n",
        "```\n",
        "You just read off the line."
      ],
      "metadata": {
        "id": "-Rbo1u71hLBd"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOKdrLgbcaLq"
      },
      "source": [
        "Let's try it! But to be sure it \"works\", we will do it in this way:\n",
        " 1. choose $a=2$, $b=1$\n",
        " 2. calculate x and y, where: $$ y = a \\cdot x + b + e, $$ where $e$ is same gaussian noise $e \\sim \\mathcal{N}(0,0.1) $ (to not make it so obvious)\n",
        " 3. split the dataset into train data and test data\n",
        " 4. fit model to training data (i.e. estimate the parameters $\\hat{a}$, $\\hat{b}$ from training data)\n",
        " 5. plot results, calculate errors\n",
        "\n",
        "If we manage to do everything all right, this should hold: $\\hat{a} = a $, $\\hat{b} = b$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {},
        "id": "5F7NqrN-caLr"
      },
      "outputs": [],
      "source": [
        "# Set coefficients\n",
        "a = 2\n",
        "b = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {},
        "id": "aM__yLTHcaLr"
      },
      "outputs": [],
      "source": [
        "# Generate random data with Gaussian noise\n",
        "np.random.seed(0)\n",
        "num_samples = 10\n",
        "x = np.random.rand(num_samples)\n",
        "noise = np.random.normal(0, 0.1, num_samples)\n",
        "y = a * x + b + noise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {},
        "id": "p1FUX6qwcaLr"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# Split dataset into training and testing sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {},
        "id": "NX_gl3U9caLr"
      },
      "outputs": [],
      "source": [
        "x_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {},
        "id": "kx4FAsMycaLr"
      },
      "outputs": [],
      "source": [
        "# Reshape x arrays to be 2D (technical part, required by scikit-learn)\n",
        "x_train = x_train.reshape(-1, 1)\n",
        "x_test = x_test.reshape(-1, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eiwpkKkfcaLr"
      },
      "source": [
        "( In scikit-learn, the input data for training a linear regression model is expected to be a 2D array where each row represents a sample and each column represents a feature.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {},
        "id": "ambEryDQcaLr"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Create and fit linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(x_train, y_train)\n",
        "\n",
        "# Get the estimated coefficients\n",
        "a_hat = model.coef_[0]\n",
        "b_hat = model.intercept_\n",
        "\n",
        "# Print the estimated coefficients\n",
        "print(\"Estimated coefficient a:\", a_hat)\n",
        "print(\"Estimated coefficient b:\", b_hat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {},
        "id": "cH5LHsezcaLs"
      },
      "outputs": [],
      "source": [
        "# Plot the data and regression line\n",
        "plt.scatter(x_train, y_train, color='blue', label='Training Data')\n",
        "plt.scatter(x_test, y_test, color='red', label='Testing Data')\n",
        "plt.plot(x_train, model.predict(x_train), color='green', label='Regression Line')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.title('Linear Regression')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {},
        "id": "zfdRN3WTcaLs"
      },
      "outputs": [],
      "source": [
        "# 6. Evaluate predictions (numerically)\n",
        "predictions = model.predict(x_test)\n",
        "mse = np.mean((y_test - predictions) ** 2)\n",
        "print(\"Mean squared error:\", mse)\n",
        "\n",
        "from sklearn import metrics\n",
        "\n",
        "accu = metrics.r2_score(y_test, predictions)\n",
        "print(f\"Accuracy (r2 score): {accu*100} %\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {},
        "id": "6rdeAfTPcaLs"
      },
      "outputs": [],
      "source": [
        "# Computing the errors in parameter estimation:\n",
        "error_of_a = np.abs(a - a_hat)\n",
        "error_of_b = np.abs(b - b_hat)\n",
        "\n",
        "print(f\"Error of 'a' is {error_of_a:.5f} and error of 'b' is {error_of_b:.5f}.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {},
        "id": "RKrYk9AAcaLs"
      },
      "outputs": [],
      "source": [
        "my_values = [-1, 0.3, 0.56, 7, 1000]\n",
        "for value in my_values:\n",
        "    value = np.array([value]).reshape(-1, 1)\n",
        "    print(f\"Prediction in {value} is {model.predict(value)}, while real value is {a*value + b}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DLLvy0WcaLt"
      },
      "source": [
        "üî• What do we see here? It seems our linear model predicts nicely only for values in range of data it has been trained on. And it predicts badly on *outliers*.\n",
        "\n",
        "Well that's inevitable üòï. Any model struggles to predict something it has never seen, and *the further* new value is from training data, *the worse* is the prediction.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_BXtvozcaLt"
      },
      "source": [
        "We have 2 ways to deal with it:\n",
        " - increase the number of data in training dataset (the more, the better)\n",
        " - increase the range of training dataset\n",
        "\n",
        "Yet - of course any model has its limits, and we cannot expect the same precision for *any* input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yY3arpdjcaLt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ONEls8ecaLt"
      },
      "source": [
        "### statsmodels (statistically about regression)\n",
        "<a href=\"https://www.statsmodels.org/stable/index.html\"><img src=\"https://www.statsmodels.org/stable/_images/statsmodels-logo-v2-horizontal.svg\" alt=\"banner\" width=\"380\" align=\"right\"></a>\n",
        " = library for different statistical models\n",
        " - statistical approach\n",
        " - under active development\n",
        " - best of 2 worlds: Python and R\n",
        " - operates on `pandas.DataFrame`-s\n",
        " - homepage: [here](https://www.statsmodels.org/stable/index.html)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Anv5l2hFcaLt"
      },
      "source": [
        "**Linear regression**\n",
        " - is a statistical method used to model the relationship between a *dependent variable* and one or more *independent variables* by *fitting a straight line* to the observed data points.\n",
        " - aim: to find the best-fitting line that minimizes the difference between the actual values and the predicted values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7AV1thE8caLt"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%pip install statsmodels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xhc7ffo1caLu"
      },
      "outputs": [],
      "source": [
        "import statsmodels.formula.api as smf\n",
        "import statsmodels.api as sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {},
        "id": "e6I34iyycaLu"
      },
      "outputs": [],
      "source": [
        "# Define DataFrame from x_train and y_train\n",
        "df_nums = pd.DataFrame(data=x_train, columns=['x_train'])\n",
        "df_nums['y_train'] = y_train\n",
        "print(df_nums.head(3))\n",
        "\n",
        "\n",
        "# Create and fit the model using formula\n",
        "import statsmodels.formula.api as smf\n",
        "model_nums = smf.ols(formula='y_train ~ x_train', data=df_nums)\n",
        "results_nums = model_nums.fit()\n",
        "\n",
        "# Print summary\n",
        "print(results_nums.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {},
        "id": "vvqr_tVUcaLu"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import statsmodels.api as sm\n",
        "\n",
        "fig = plt.figure(figsize=(7,5), dpi=100)\n",
        "ax = fig.add_subplot(111)\n",
        "sm.graphics.plot_ccpr(results_nums, \"x_train\", ax=ax)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXhIsOtQcaLu"
      },
      "source": [
        "Explanation: [https://www.geeksforgeeks.org/solving-linear-regression-in-python/](https://www.geeksforgeeks.org/solving-linear-regression-in-python/) ... building the table from the very beginning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Lr1u7Q4caLu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAOWdt8rcaLv"
      },
      "source": [
        "#### But how it really works inside, \"under the hood\"?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {},
        "id": "jBMT4j4OcaLv"
      },
      "outputs": [],
      "source": [
        "# Standalone simple linear regression example\n",
        "from math import sqrt\n",
        "\n",
        "# Calculate root mean squared error\n",
        "def rmse_metric(actual, predicted):\n",
        "\t\"\"\"returns mean square error\"\"\"\n",
        "\tsum_error = 0.0\n",
        "\tfor i in range(len(actual)):\n",
        "\t\tprediction_error = predicted[i] - actual[i]\n",
        "\t\tsum_error += (prediction_error ** 2)\n",
        "\tmean_error = sum_error / float(len(actual))\n",
        "\treturn sqrt(mean_error)\n",
        "\n",
        "# Evaluate regression algorithm on training dataset\n",
        "def evaluate_algorithm(dataset, algorithm):\n",
        "\ttest_set = list()\n",
        "\tfor row in dataset:\n",
        "\t\trow_copy = list(row)\n",
        "\t\trow_copy[-1] = None\n",
        "\t\ttest_set.append(row_copy)\n",
        "\tpredicted = algorithm(dataset, test_set)\n",
        "\tprint(predicted)\n",
        "\tactual = [row[-1] for row in dataset]\n",
        "\trmse = rmse_metric(actual, predicted)\n",
        "\treturn rmse\n",
        "\n",
        "# Calculate the mean value of a list of numbers\n",
        "def mean(values):\n",
        "\treturn sum(values) / float(len(values))\n",
        "\n",
        "# Calculate covariance between x and y\n",
        "def covariance(x, mean_x, y, mean_y):\n",
        "\tcovar = 0.0\n",
        "\tfor i in range(len(x)):\n",
        "\t\tcovar += (x[i] - mean_x) * (y[i] - mean_y)\n",
        "\treturn covar\n",
        "\n",
        "# Calculate the variance of a list of numbers\n",
        "def variance(values, mean):\n",
        "\treturn sum([(x-mean)**2 for x in values])\n",
        "\n",
        "# Calculate coefficients\n",
        "def coefficients(dataset):\n",
        "\tx = [row[0] for row in dataset]\n",
        "\ty = [row[1] for row in dataset]\n",
        "\tx_mean, y_mean = mean(x), mean(y)\n",
        "\tb1 = covariance(x, x_mean, y, y_mean) / variance(x, x_mean)\n",
        "\tb0 = y_mean - b1 * x_mean\n",
        "\treturn [b0, b1]\n",
        "\n",
        "# Simple linear regression algorithm\n",
        "def simple_linear_regression(train, test):\n",
        "\tpredictions = list()\n",
        "\tb0, b1 = coefficients(train)\n",
        "\tfor row in test:\n",
        "\t\tyhat = b0 + b1 * row[0]\n",
        "\t\tpredictions.append(yhat)\n",
        "\treturn predictions\n",
        "\n",
        "# Test simple linear regression\n",
        "dataset = [[1, 1], [2, 3], [4, 3], [3, 2], [5, 5]]\n",
        "rmse = evaluate_algorithm(dataset, simple_linear_regression)\n",
        "print(f\"RMSE: {rmse:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2RiHdbbBcaLv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSHOQo9vcaLv"
      },
      "source": [
        "### More real example:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLPzEwhtcaLv"
      },
      "source": [
        "#### Wine regression\n",
        "(Cortez,Paulo, Cerdeira,A., Almeida,F., Matos,T., and Reis,J.. (2009). Wine Quality. UCI Machine Learning Repository. https://doi.org/10.24432/C56S3T., [source of data](https://archive.ics.uci.edu/dataset/186/wine+quality))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {},
        "id": "RGC2evEFcaLw"
      },
      "outputs": [],
      "source": [
        "df_wine = pd.read_csv(\"https://gist.githubusercontent.com/aleksejalex/e63e1f9cf8f9ff90e70dff71e0228ab7/raw/d27a61ce5a76dfa9f02f977d32381ff3a3eb9f86/wine.csv\", delimiter=';')\n",
        "df_wine.describe(include='all')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "metadata": {},
        "id": "Z750YbrBcaLw"
      },
      "outputs": [],
      "source": [
        "sns.pairplot(df_wine)\n",
        "plt.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LgZTIbNJcaLw"
      },
      "outputs": [],
      "source": [
        "model_wine = smf.ols(formula='quality ~ alcohol', data=df_wine)\n",
        "results_wine = model_wine.fit()\n",
        "\n",
        "# Print summary\n",
        "print(results_wine.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mna_ufTccaLw"
      },
      "source": [
        "So called saturated model (perfect fit: as much variables as datapoints):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PiSD58QwcaLx"
      },
      "outputs": [],
      "source": [
        "model_wine_satur = smf.ols(formula='quality ~ fixed_acidity*volatile_acidity*citric_acid*residual_sugar*chlorides*free_sulfur_dioxide*total_sulfur_dioxide*density*pH*sulphates*alcohol', data=df_wine)\n",
        "results_wine_satur = model_wine_satur.fit()\n",
        "\n",
        "# Print summary\n",
        "print(results_wine_satur.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VocLq94XcaLx"
      },
      "source": [
        "Saturated model, no interactions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "STTh77ZscaLx"
      },
      "outputs": [],
      "source": [
        "import statsmodels.formula.api as smf\n",
        "\n",
        "# Define the formula for the linear regression model with interactions up to order 3\n",
        "formula = 'quality ~ (fixed_acidity + volatile_acidity + citric_acid + residual_sugar + chlorides + free_sulfur_dioxide + total_sulfur_dioxide + density + pH + sulphates + alcohol)**3'\n",
        "\n",
        "# Fit the model\n",
        "model_wine_satur_no_iter = smf.ols(formula=formula, data=df_wine)\n",
        "results_wine_satur_no_iter = model_wine_satur_no_iter.fit()\n",
        "\n",
        "# Print summary\n",
        "print(results_wine_satur_no_iter.summary())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XGW5rVdIcaLy"
      },
      "outputs": [],
      "source": [
        "model_wine_satur_no_iter = smf.ols(formula='quality ~ fixed_acidity:volatile_acidity:citric_acid:residual_sugar:chlorides:free_sulfur_dioxide:total_sulfur_dioxide:density:pH:sulphates:alcohol', data=df_wine)\n",
        "results_wine_satur_no_iter = model_wine_satur_no_iter.fit()\n",
        "\n",
        "# Print summary\n",
        "print(results_wine_satur_no_iter.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIS939DicaLy"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B5b_NTA3caLy"
      },
      "source": [
        "========================================================================================================================="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6cNRYNMtcaLy"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yxj0FvfvcaLy"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Biu2xvlzcaLy"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_vqRA4kTcaLy"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hd-VmveecaLy"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "generative_ai_disabled": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}